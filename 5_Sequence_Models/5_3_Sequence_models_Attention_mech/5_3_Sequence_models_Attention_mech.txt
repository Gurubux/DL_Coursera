	-------------------------------------------------------------------------------------------------------------------------
"SEQUENCE MODELS & ATTENTION MECHANISM"
Sequence models can be augmented using an attention mechanism. This algorithm will help your model understand where it should focus its attention given a sequence of inputs. This week, you will also learn about speech recognition and how to deal with audio data.




--------------------------------------------------------------------------------------------------------------
VARIOUS SEQUENCE TO SEQUENCE ARCHITECTURES
--------------------------------------------------------------------------------------------------------------

Basic Models

Picking the most likely sentence

Beam Search

Refinements to Beam Search

Error analysis in beam search
	BeamSearch_ErrorAnalysis.jpg

Bleu Score (optional)
Bilingual evaluation Understudy
Intuition is so long as the machine generated translation is pretty close to any of the references provided by humans, then it will get a high BLEU score.
So the BLEU score is a useful single real number evaluation metric to use whenever you want your algorithm to generate a piece of text. And you want to see whether it has similar meaning as a reference piece of text generated by humans. This is not used for speech recognition, because in speech recognition, there`s usually one ground truth. And you just use other measures to see if you got the speech transcription on pretty much, exactly word for word correct. But for things like image captioning, and multiple captions for a picture, it could be about equally good or for machine translations. There are multiple translations, but equally good. The BLEU score gives you a way to evaluate that automatically and therefore speed up your development.

Attention Model Intuition

Attention Model
The attention model allows a neural network to pay attention to only part of an input sentence while it`s generating a translation, much like a human translator might.



--------------------------------------------------------------------------------------------------------------
SPEECH RECOGNITION - AUDIO DATA
--------------------------------------------------------------------------------------------------------------
Speech recognition
Trigger Word Detection




--------------------------------------------------------------------------------------------------------------
Conclusion and thank you
--------------------------------------------------------------------------------------------------------------




--------------------------------------------------------------------------------------------------------------
QUIZ: Sequence models & Attention mechanism
--------------------------------------------------------------------------------------------------------------



--------------------------------------------------------------------------------------------------------------
Notebook: Neural Machine Translation with Attention
--------------------------------------------------------------------------------------------------------------
You will build a Neural Machine Translation (NMT) model to translate human readable dates ("25th of June, 2009") into machine readable dates ("2009-06-25"). 
You will do this using an attention model, one of the most sophisticated sequence to sequence models.
NVIDIA`s Deep Learning Institute

1 - Translating human readable dates into machine readable dates
The network will input a date written in a variety of possible formats (e.g. "the 29th of August 1958", "03/30/1968", "24 JUNE 1987") and translate them into standardized, machine readable dates (e.g. "1958-08-29", "1968-03-30", "1987-06-24"). We will have the network learn to output dates in the common machine-readable format YYYY-MM-DD.
	1.1 - Dataset

2 - Neural machine translation with attention
	2.1 - Attention mechanism
3 - Visualizing Attention!(OPTIONAL/UNGRADED)
	3.1 - Getting the activations from the network




\1 - Translating human readable dates into machine readable dates
The network will input a date written in a variety of possible formats (e.g. "the 29th of August 1958", "03/30/1968", "24 JUNE 1987") and translate them into standardized, machine readable dates (e.g. "1958-08-29", "1968-03-30", "1987-06-24"). We will have the network learn to output dates in the common machine-readable format YYYY-MM-DD.
	\1.1 - Dataset
m = 10000
dataset, human_vocab, machine_vocab, inv_machine_vocab = load_dataset(m)
>>>
100%|██████████| 10000/10000 [00:00<00:00, 16214.56it/s]

dataset[:10],human_vocab,machine_vocab,inv_machine_vocab
>>>
([('9 may 1998', '1998-05-09'),
  ('10.09.70', '1970-09-10'),
  ('4/28/90', '1990-04-28'),
  ('thursday january 26 1995', '1995-01-26'),
  ('monday march 7 1983', '1983-03-07'),
  ('sunday may 22 1988', '1988-05-22'),
  ('tuesday july 8 2008', '2008-07-08'),
  ('08 sep 1999', '1999-09-08'),
  ('1 jan 1981', '1981-01-01'),
  ('monday may 22 1995', '1995-05-22')],
 {' ': 0,
  '.': 1,
  '/': 2,
  '0': 3,
  '1': 4,
  '2': 5,
  '3': 6,
  '4': 7,
  '5': 8,
  '6': 9,
  '7': 10,
  '8': 11,
  '9': 12,
  '<pad>': 36,
  '<unk>': 35,
  'a': 13,
  'b': 14,
  'c': 15,
  'd': 16,
  'e': 17,
  'f': 18,
  'g': 19,
  'h': 20,
  'i': 21,
  'j': 22,
  'l': 23,
  'm': 24,
  'n': 25,
  'o': 26,
  'p': 27,
  'r': 28,
  's': 29,
  't': 30,
  'u': 31,
  'v': 32,
  'w': 33,
  'y': 34},
 {'-': 0,
  '0': 1,
  '1': 2,
  '2': 3,
  '3': 4,
  '4': 5,
  '5': 6,
  '6': 7,
  '7': 8,
  '8': 9,
  '9': 10},
 {0: '-',
  1: '0',
  2: '1',
  3: '2',
  4: '3',
  5: '4',
  6: '5',
  7: '6',
  8: '7',
  9: '8',
  10: '9'})


Tx = 30
Ty = 10
X, Y, Xoh, Yoh = preprocess_data(dataset, human_vocab, machine_vocab, Tx, Ty)

print("X.shape:", X.shape)
print("Y.shape:", Y.shape)
print("Xoh.shape:", Xoh.shape)
print("Yoh.shape:", Yoh.shape)
Source date: 9 may 1998
Target date: 1998-05-09

Source after preprocessing (indices): [12  0 24 13 34  0  4 12 12 11 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36
 36 36 36 36 36]
Target after preprocessing (indices): [ 2 10 10  9  0  1  6  0  1 10]

Source after preprocessing (one-hot): [[ 0.  0.  0. ...,  0.  0.  0.]
 [ 1.  0.  0. ...,  0.  0.  0.]
 [ 0.  0.  0. ...,  0.  0.  0.]
 ..., 
 [ 0.  0.  0. ...,  0.  0.  1.]
 [ 0.  0.  0. ...,  0.  0.  1.]
 [ 0.  0.  0. ...,  0.  0.  1.]]
Target after preprocessing (one-hot): [[ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]
 [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
 [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
 [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]
 [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
 [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]]

\2 - Neural machine translation with attention
"The attention mechanism tells a Neural Machine Translation model where it should pay attention to at any step."
	\2.1 - Attention mechanism
Figure 1: Neural machine translation with attention
attention_model.jpg
one_step_attention()
model()



# Defined shared layers as global variables
repeator = RepeatVector(Tx)
concatenator = Concatenate(axis=-1)
densor1 = Dense(10, activation = "tanh")
densor2 = Dense(1, activation = "relu")
activator = Activation(softmax, name='attention_weights') # We are using a custom softmax(axis = 1) loaded in this notebook
dotor = Dot(axes = 1)

# GRADED FUNCTION: one_step_attention

def one_step_attention(a, s_prev):

    # Use repeator to repeat s_prev to be of shape (m, Tx, n_s) so that you can concatenate it with all hidden states "a" (≈ 1 line)
    s_prev = repeator(s_prev)
    # Use concatenator to concatenate a and s_prev on the last axis (≈ 1 line)
    concat = concatenator([a, s_prev])
    # Use densor1 to propagate concat through a small fully-connected neural network to compute the "intermediate energies" variable e. (≈1 lines)
    e = densor1(concat)
    # Use densor2 to propagate e through a small fully-connected neural network to compute the "energies" variable energies. (≈1 lines)
    energies = densor2(e)
    # Use "activator" on "energies" to compute the attention weights "alphas" (≈ 1 line)
    alphas = activator(energies)
    # Use dotor together with "alphas" and "a" to compute the context vector to be given to the next (post-attention) LSTM-cell (≈ 1 line)
    context = dotor([alphas,a])
    ### END CODE HERE ###
    
    return context



n_a = 32
n_s = 64
post_activation_LSTM_cell = LSTM(n_s, return_state = True)
output_layer = Dense(len(machine_vocab), activation=softmax)

# GRADED FUNCTION: model

def model(Tx, Ty, n_a, n_s, human_vocab_size, machine_vocab_size):
    # Define the inputs of your model with a shape (Tx,)
    # Define s0 and c0, initial hidden state for the decoder LSTM of shape (n_s,)
    X = Input(shape=(Tx, human_vocab_size))
    s0 = Input(shape=(n_s,), name='s0')
    c0 = Input(shape=(n_s,), name='c0')
    s = s0
    c = c0
    
    # Initialize empty list of outputs
    outputs = []
    
    ### START CODE HERE ###
    
    # Step 1: Define your pre-attention Bi-LSTM. Remember to use return_sequences=True. (≈ 1 line)
    a = Bidirectional(LSTM(n_a, return_sequences=True))(X)
    
    # Step 2: Iterate for Ty steps
    for t in range(Ty):
    
        # Step 2.A: Perform one step of the attention mechanism to get back the context vector at step t (≈ 1 line)
        context = one_step_attention(a, s)
        
        # Step 2.B: Apply the post-attention LSTM cell to the "context" vector.
        # Don't forget to pass: initial_state = [hidden state, cell state] (≈ 1 line)
        s, _, c = post_activation_LSTM_cell(context,initial_state=[s, c])
        
        # Step 2.C: Apply Dense layer to the hidden state output of the post-attention LSTM (≈ 1 line)
        out = output_layer(s)
        
        # Step 2.D: Append "out" to the "outputs" list (≈ 1 line)
        outputs.append(out)
    
    # Step 3: Create model instance taking three inputs and returning the list of outputs. (≈ 1 line)
    model = Model(inputs=[X, s0, c0], outputs=outputs)
    
    ### END CODE HERE ###
    
    return model

model = model(Tx, Ty, n_a, n_s, len(human_vocab), len(machine_vocab))
model.summary()


opt = Adam(lr=0.005, beta_1=0.9, beta_2=0.999, decay=0.01)
model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])

s0 = np.zeros((m, n_s))
c0 = np.zeros((m, n_s))
outputs = list(Yoh.swapaxes(0,1))


model.fit([Xoh, s0, c0], outputs, epochs=1, batch_size=100)
>>>
Epoch 1/1
10000/10000 [==============================] - 38s - loss: 16.4747 - dense_5_loss_1: 1.2802 - dense_5_loss_2: 1.0292 - dense_5_loss_3: 1.7165 - dense_5_loss_4: 2.6735 - dense_5_loss_5: 0.7765 - dense_5_loss_6: 1.2497 - dense_5_loss_7: 2.6822 - dense_5_loss_8: 0.8416 - dense_5_loss_9: 1.6894 - dense_5_loss_10: 2.5358 - dense_5_acc_1: 0.4733 - dense_5_acc_2: 0.6892 - dense_5_acc_3: 0.3079 - dense_5_acc_4: 0.0785 - dense_5_acc_5: 0.9138 - dense_5_acc_6: 0.3616 - dense_5_acc_7: 0.0610 - dense_5_acc_8: 0.9650 - dense_5_acc_9: 0.2271 - dense_5_acc_10: 0.0950    



\3 - Visualizing Attention!(OPTIONAL/UNGRADED)
Figure 8: Full Attention Map
date_attention_map.jpg
"Notice how the output ignores the "Saturday" portion of the input. None of the output timesteps are paying much attention to that portion of the input. We see also that 9 has been translated as 09 and May has been correctly translated into 05, with the output paying attention to the parts of the input it needs to to make the translation. The year mostly requires it to pay attention to the input's "18" in order to generate "2018.""

	\3.1 - Getting the activations from the network




--------------------------------------------------------------------------------------------------------------
Notebook: Trigger word detection
--------------------------------------------------------------------------------------------------------------
In this week`s videos, you learned about applying deep learning to speech recognition. In this assignment, you will construct a speech dataset and implement an algorithm for trigger word detection (sometimes also called keyword detection, or wakeword detection). Trigger word detection is the technology that allows devices like Amazon Alexa, Google Home, Apple Siri, and Baidu DuerOS to wake up upon hearing a certain word.
For this exercise, our trigger word will be "Activate." Every time it hears you say "activate," it will make a "chiming" sound. By the end of this assignment, you will be able to record a clip of yourself talking, and have the algorithm trigger a chime when it detects you saying "activate."

After completing this assignment, perhaps you can also extend it to run on your laptop so that every time you say "activate" it starts up your favorite app, or turns on a network connected lamp in your house, or triggers some other event?
In this assignment you will learn to:
	- Structure a speech recognition project
	- Synthesize and process audio recordings to create train/dev datasets
	- Train a trigger word detection model and make predictions



1 - Data synthesis: Creating a speech dataset
	1.1 - Listening to the data
IPython.display.Audio("./raw_data/activates/1.wav")
IPython.display.Audio("./raw_data/negatives/4.wav")
IPython.display.Audio("./raw_data/backgrounds/1.wav")
	1.2 - From audio recordings to spectrograms
You can think of an audio recording is a long list of numbers measuring the little air pressure changes detected by the microphone. We will use audio sampled at 44100 Hz (or 44100 Hertz). This means the microphone gives us 44100 numbers per second. Thus, a 10 second audio clip is represented by 441000 numbers (=  10×4410010×44100 ).
	1.3 - Generating a single training example
	1.4 - Full training set
	1.5 - Development set
2 - Model
	2.1 - Build the model
	2.2 - Fit the model
	2.3 - Test the model
3 - Making Predictions
	3.1 - Test on dev examples
4 - Try your own example!(OPTIONAL/UNGRADED)

