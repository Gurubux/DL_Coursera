@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ WEEK - 1 @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
------------------------------------------INTRODUCTION TO ML STRATEGY------------------------------------------
--------------------------------------------------------------------------------------------------------------------------
WHY ML STRATEGY

Improving Accuracy of ML Algo
"https://raw.githubusercontent.com/Gurubux/DL_Coursera/master/3_Structuring_Machine_Learning_Projects/w1_1_ImprovingAccuracyMLAlgo.PNG"
--------------------------------------------------------------------------------------------------------------------------
ORTHOGONALIZATION
90 degree
Changing one tuning parameter should only tune that parameter without affecting others - Orthogonalization
So I hope that gives you a sense of what orthogonalization means. Just like when you look at the TV image, it`s nice if you can say, my TV image is too wide, so I`m going to tune this knob, or it`s too tall, so I`m going to tune that knob, or it`s too trapezoidal, so I`m going to have to tune that knob. In machine learning, it`s nice if you can look at your system and say, this piece of it is wrong. It does not do well on the training set, it does not do well on the dev set, it does not do well on the test set, or it`s doing well on the test set but just not in the real world. But figure out exactly what`s wrong, and then have exactly one knob, or a specific set of knobs that helps to just solve that problem that is limiting the performance of machine learning system. So what we`re going to do this week and next week is go through how to diagnose what exactly is the bottleneck to your system`s performance. As well as identify the specific set of knobs you could use to tune your system to improve that aspect of its performance.
--------------------------------------------------------------------------------------------------------------------------
------------------------------------------SETTING UP YOUR GOAL------------------------------------------------------------
--------------------------------------------------------------------------------------------------------------------------
SINGLE NUMBER EVALUATION METRIC

--------------------------------------------------------------------------------------------------------------------------
SATISFICING AND OPTIMIZING METRIC

--------------------------------------------------------------------------------------------------------------------------
TRAIN/DEV/TEST DISTRIBUTIONS
Dev and Test set should be From same distribution
"https://raw.githubusercontent.com/Gurubux/DL_Coursera/master/3_Structuring_Machine_Learning_Projects/w1_5_Train_dev_test_set_Distribution.PNG"
--------------------------------------------------------------------------------------------------------------------------
SIZE OF THE DEV AND TEST SETS
"https://raw.githubusercontent.com/Gurubux/DL_Coursera/master/3_Structuring_Machine_Learning_Projects/w1_6_Train_dev_test_set_Size.PNG"

--------------------------------------------------------------------------------------------------------------------------
WHEN TO CHANGE DEV/TEST SETS AND METRICS

--------------------------------------------------------------------------------------------------------------------------
------------------------------------------COMPARING TO HUMAN-LEVEL PERFORMANCE------------------------------------------
--------------------------------------------------------------------------------------------------------------------------
WHY HUMAN-LEVEL PERFORMANCE?
Bayes Optimal Error
Manual Error Analysis
"https://raw.githubusercontent.com/Gurubux/DL_Coursera/master/3_Structuring_Machine_Learning_Projects/w1_8_Human_Level_error.PNG"
--------------------------------------------------------------------------------------------------------------------------
AVOIDABLE BIAS
"https://raw.githubusercontent.com/Gurubux/DL_Coursera/master/3_Structuring_Machine_Learning_Projects/w1_9_BIAS_reduction_techniques"
--------------------------------------------------------------------------------------------------------------------------
UNDERSTANDING HUMAN-LEVEL PERFORMANCE
"https://raw.githubusercontent.com/Gurubux/DL_Coursera/master/3_Structuring_Machine_Learning_Projects/w1_9_HUMAN-LEVEL_Error.PNG"
"https://raw.githubusercontent.com/Gurubux/DL_Coursera/master/3_Structuring_Machine_Learning_Projects/w1_9_HUMAN-LEVEL_Error_summary.PNG"
--------------------------------------------------------------------------------------------------------------------------
SURPASSING HUMAN-LEVEL PERFORMANCE
So in this example, once you`ve surpassed this 0.5% threshold, your options, your ways of making progress on the machine learning problem are just less clear. It doesn`t mean you can`t make progress, you might still be able to make significant progress, but some of the tools you have for pointing you in a clear direction just don`t work as well. 
--------------------------------------------------------------------------------------------------------------------------
IMPROVING YOUR MODEL PERFORMANCE

"https://raw.githubusercontent.com/Gurubux/DL_Coursera/master/3_Structuring_Machine_Learning_Projects/w1_11_IMPROVING_Performance_summary.PNG"

MACHINE LEARNING FLIGHT SIMULATOR
READING: READINGMACHINE LEARNING FLIGHT SIMULATOR
QUIZ: BIRD RECOGNITION IN THE CITY OF PEACETOPIA (CASE STUDY)

VIDEO ANDREJ KARPATHY
--------------------------------------------------------------------------------------------------------------------------
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ WEEK - 2 @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
------------------------------------------ERROR ANALYSIS------------------------------------------
------------------------------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------------
CARRYING OUT ERROR ANALYSIS
Out of 100 observations mis-classified as cat -(Cat Classifier), calculated the % of mis-classified category which has most impact.
For example:
	8% are Dog images
	62% are Big-Cats
	30% are blurry images
This Error Analysis helps us to get a direction of whether to better understand Dog or Big-Cats or blurry images - ( in this case Big-Cats and blurry) is worth the time and effort and is most effective.

------------------------------------------------------------------------------------------------------------------------------
CLEANING UP INCORRECTLY LABELED DATA
-Training set
	Output label y are are incorrect, in your training set. 
	If "random error"(Miss typed 0 As 1 etc) then its probably fine to leave in incorrect, but if "Systematic Error" (All white dogs are miss-classified As cats) then these needs to be fixed
-Dev set
	So for this in the above 'ERROR ANALYSIS' table add a column to capture labels that are incorrectly labeled rather than Labels that are incorrectly classified by your model, and see if has a higer impact if yes, make the changes.

-Test set
	Apply same fixing process of Dev set on test set

Fixing in Training set is avoid due to the large amount of data it has, which is ok. Also this may result in the distribution of your Train and Dev/Test set data to differ.

------------------------------------------------------------------------------------------------------------------------------
BUILD YOUR FIRST SYSTEM QUICKLY, THEN ITERATE
"BUILD YOUR FIRST SYSTEM QUICKLY, THEN ITERATE"
Use "Bias/Variance Analysis" and "Error Analysis" to prioritize your next steps.


------------------------------------------------------------------------------------------------------------------------------
------------------------------------------MISMATCHED TRAINING AND DEV/TEST SET------------------------------------------
------------------------------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------------
TRAINING AND TESTING ON DIFFERENT DISTRIBUTIONS
Training and testing on different distributions
Example:
	Training data From Webpages ~ 10,000
	Testing data From Mobile apps ~ 2,000
	Solution 1 : 
		Add both together ~ 12,000 and reshuffle and divide into 90/5/5 - 10,800/600/600 Traing/Dev/Test set
		Adv 	: Data now comes From same distribution
		DisAdv 	: A lot of Data in dev set now comes from Webpages 
				  Since 84% data is From WebPages and 26 is From Mobile apps, 504 images would be From only  WebPages and only 96 would be from Mobile Apps

	Solution 2 : (Better)
		Add 10,000 From webpages and 1,000 images Mobile apps into Train Set
		Add 1,000 images From Mobile apps , 500 each into Dev and test set 
		Adv 	: Model will aim to improve Dev set which has distributions From mobile apps, which matters
		DisAdv 	: Data now DOES NOT come From same distribution into train and Dev/test set



------------------------------------------------------------------------------------------------------------------------------
BIAS AND VARIANCE WITH MISMATCHED DATA DISTRIBUTIONS

Train Set
Train-dev Set
Dev Set
Test Set
------------------------------------------------------------------------------------------------------------------------------
ADDRESSING DATA MISMATCH
Artificial Data Synthesis -  Helps you Create more data

------------------------------------------------------------------------------------------------------------------------------
------------------------------------------LEARNING FROM MULTIPLE TASKS------------------------------------------
------------------------------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------------
TRANSFER LEARNING
One of the most powerful ideas in deep learning is that sometimes you can take knowledge the neural network has learned from one task and apply that knowledge to a separate task. So for example, maybe you could have the neural network learn to recognize objects like cats and then use that knowledge or use part of that knowledge to help you do a better job reading x-ray scans.
 Let`s take a look. Let`s say you`ve trained your neural network on image recognition. So you first take a neural network and train it on X Y pairs, where X is an image and Y is some object. An image is a cat or a dog or a bird or something else. If you want to take this neural network and adapt, or we say transfer, what is learned to a different task, such as radiology diagnosis, meaning really reading X-ray scans, what you can do is take this last output layer of the neural network and just delete that and delete also the weights feeding into that last output layer and create a new set of randomly initialized weights just for the last layer and have that now output radiology diagnosis. So to be concrete, during the first phase of training when you`re training on an image recognition task, you train all of the usual parameters for the neural network, all the weights, all the layers and you have something that now learns to make image recognition predictions. Having trained that neural network, what you now do to implement transfer learning is swap in a new data set X Y, where now these are radiology images. And Y are the diagnoses you want to predict and what you do is initialize the last layers` weights. Let`s call that W.L. and P.L. randomly. And now, retrain the neural network on this new data set, on the new radiology data set. You have a couple options of how you retrain neural network with radiology data. You might, if you have a small radiology dataset, you might want to just retrain the weights of the last layer, just W.L. P.L., and keep the rest of the parameters fixed.
 
 The "rule of thumb" is maybe if you have a small data set, then just retrain the one last layer at the output layer. Or maybe that last one or two layers. But if you have a lot of data, then maybe you can retrain all the parameters in the network. And if you retrain all the parameters in the neural network, then this initial phase of training on image recognition is sometimes called pre-training, because you`re using image recognitions data to pre-initialize or really pre-train the weights of the neural network. And then if you are updating all the weights afterwards, then training on the radiology data sometimes that`s called fine tuning.
Pre-Training
Fine Tuning

"https://raw.githubusercontent.com/Gurubux/DL_Coursera/master/3_Structuring_Machine_Learning_Projects/TransferLearning.PNG"
"https://raw.githubusercontent.com/Gurubux/DL_Coursera/master/3_Structuring_Machine_Learning_Projects/TransferLearning_1.PNG"
"https://raw.githubusercontent.com/Gurubux/DL_Coursera/master/3_Structuring_Machine_Learning_Projects/TransferLearning_2.PNG"
------------------------------------------------------------------------------------------------------------------------------
MULTI-TASK LEARNING
So whereas in transfer learning, you have a sequential process where you learn From task A and then transfer that to task B. In multi-task learning, you start off simultaneously, trying to have one neural network do several things at the same time. And then each of these task helps hopefully all of the other task. 

------------------------------------------------------------------------------------------------------------------------------
------------------------------------------END-TO-END DEEP LEARNING------------------------------------------
------------------------------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------------
WHAT IS END-TO-END DEEP LEARNING?
Two ways to achieve classification
	1. Break A Problem into different problems like 
			  X 	 	 	 	 	  	 	 	 	 	 	      Y
			Audio ---> Features ---> Phenemes ---> Words ---> Transcript

	2. END-TO-END DEEP LEARNING
		      X 	 	 	 	 	  	 	 	 	 	 	      Y
			Audio ------------------------------------------> Transcript

Examples : 
	Face Recognition
	MAchine Translation
	Estimating Child`s Age Using X-ray image of hand

------------------------------------------------------------------------------------------------------------------------------
WHETHER TO USE END-TO-END DEEP LEARNING
Pros and Cons :
	Pros : 
		1. Lets Data Speak
		2. Less hand designing of Components needed

	Cons :
		1. Need large amount of data to Go From X --> You
		2. Excludes potentially usefully hand-designed components.

"KEY QUESTION"
	Do you have sufficient data to learn the function of the complexity needed to map from X to Y?


Less promising

MACHINE LEARNING FLIGHT SIMULATOR
QUIZ: AUTONOMOUS DRIVING (CASE STUDY)


VIDEO - RUSLAN SALAKHUTDINOV




"https://www.coursera.org/account/accomplishments/verify/SC85D5HGRSWQ"






KEY POINTS
W1
ML-Strategy
Orthogonalization
Precision
Accuracy
Recall
F1-score
2/(1/P)+(1/R)
harmonic-mean
train/dev/test
Optimizing
Satisfying
dev/test_Same_Dist
70/30
60/20/20
Classification-error
Human-level
Bayes-optimal-error
Avaoidable-bias
Avoidable_bias--Human-TrainError
Variance--Train-DevError
Train-DevError--MoreData-Regularization
Human-TrainError--Adam_Rms_Momentum

W2
Parallel
CleanUp
Train/test_Different_Dist
Data_Mismatch-Error
TransferLearning
Multi-TaskLearning
Flight-Simulator







