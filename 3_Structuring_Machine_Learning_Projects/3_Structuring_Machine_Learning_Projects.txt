@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ WEEK - 1 @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
------------------------------------------INTRODUCTION TO ML STRATEGY------------------------------------------
--------------------------------------------------------------------------------------------------------------------------
WHY ML STRATEGY

Improving Accuracy of ML Algo
"https://raw.githubusercontent.com/Gurubux/DL_Coursera/master/3_Structuring_Machine_Learning_Projects/ImprovingAccuracyMLAlgo.PNG"
--------------------------------------------------------------------------------------------------------------------------
ORTHOGONALIZATION
90 degree
Changing one tuning parameter should only tune that parameter without affecting others - Orthogonalization
So I hope that gives you a sense of what orthogonalization means. Just like when you look at the TV image, it`s nice if you can say, my TV image is too wide, so I`m going to tune this knob, or it`s too tall, so I`m going to tune that knob, or it`s too trapezoidal, so I`m going to have to tune that knob. In machine learning, it`s nice if you can look at your system and say, this piece of it is wrong. It does not do well on the training set, it does not do well on the dev set, it does not do well on the test set, or it`s doing well on the test set but just not in the real world. But figure out exactly what`s wrong, and then have exactly one knob, or a specific set of knobs that helps to just solve that problem that is limiting the performance of machine learning system. So what we`re going to do this week and next week is go through how to diagnose what exactly is the bottleneck to your system`s performance. As well as identify the specific set of knobs you could use to tune your system to improve that aspect of its performance.
--------------------------------------------------------------------------------------------------------------------------
------------------------------------------SETTING UP YOUR GOAL------------------------------------------------------------
--------------------------------------------------------------------------------------------------------------------------
SINGLE NUMBER EVALUATION METRIC

--------------------------------------------------------------------------------------------------------------------------
SATISFICING AND OPTIMIZING METRIC

--------------------------------------------------------------------------------------------------------------------------
TRAIN/DEV/TEST DISTRIBUTIONS
Dev and Test set should be From same distribution
"https://raw.githubusercontent.com/Gurubux/DL_Coursera/master/3_Structuring_Machine_Learning_Projects/w1_5_Train_dev_test_set_Distribution.PNG"
--------------------------------------------------------------------------------------------------------------------------
SIZE OF THE DEV AND TEST SETS
"https://raw.githubusercontent.com/Gurubux/DL_Coursera/master/3_Structuring_Machine_Learning_Projects/w1_6_Train_dev_test_set_Size.PNG"

--------------------------------------------------------------------------------------------------------------------------
WHEN TO CHANGE DEV/TEST SETS AND METRICS

--------------------------------------------------------------------------------------------------------------------------
------------------------------------------COMPARING TO HUMAN-LEVEL PERFORMANCE------------------------------------------
--------------------------------------------------------------------------------------------------------------------------
WHY HUMAN-LEVEL PERFORMANCE?
Bayes Optimal Error
Manual Error Analysis
"https://raw.githubusercontent.com/Gurubux/DL_Coursera/master/3_Structuring_Machine_Learning_Projects/w1_8_Human_Level_error.PNG"
--------------------------------------------------------------------------------------------------------------------------
AVOIDABLE BIAS
"https://raw.githubusercontent.com/Gurubux/DL_Coursera/master/3_Structuring_Machine_Learning_Projects/w1_9_BIAS_reduction_techniques"
--------------------------------------------------------------------------------------------------------------------------
UNDERSTANDING HUMAN-LEVEL PERFORMANCE
"https://raw.githubusercontent.com/Gurubux/DL_Coursera/master/3_Structuring_Machine_Learning_Projects/w1_9_HUMAN-LEVEL_Error.PNG"
"https://raw.githubusercontent.com/Gurubux/DL_Coursera/master/3_Structuring_Machine_Learning_Projects/w1_9_HUMAN-LEVEL_Error_summary.PNG"
--------------------------------------------------------------------------------------------------------------------------
SURPASSING HUMAN-LEVEL PERFORMANCE
So in this example, once you`ve surpassed this 0.5% threshold, your options, your ways of making progress on the machine learning problem are just less clear. It doesn`t mean you can`t make progress, you might still be able to make significant progress, but some of the tools you have for pointing you in a clear direction just don`t work as well. 
--------------------------------------------------------------------------------------------------------------------------
IMPROVING YOUR MODEL PERFORMANCE

"https://raw.githubusercontent.com/Gurubux/DL_Coursera/master/3_Structuring_Machine_Learning_Projects/w1_11_IMPROVING_Performance_summary.PNG"

MACHINE LEARNING FLIGHT SIMULATOR
READING: READINGMACHINE LEARNING FLIGHT SIMULATOR
QUIZ: BIRD RECOGNITION IN THE CITY OF PEACETOPIA (CASE STUDY)

VIDEO ANDREJ KARPATHY
--------------------------------------------------------------------------------------------------------------------------
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ WEEK - 2 @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
------------------------------------------ERROR ANALYSIS------------------------------------------
------------------------------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------------
CARRYING OUT ERROR ANALYSIS
Out of 100 observations mis-classified as cat -(Cat Classifier), calculated the % of mis-classified category which has most impact.
For example:
	8% are Dog images
	62% are Big-Cats
	30% are blurry images
This Error Analysis helps us to get a direction of whether to better understand Dog or Big-Cats or blurry images - ( in this case Big-Cats and blurry) is worth the time and effort and is most effective.

------------------------------------------------------------------------------------------------------------------------------
CLEANING UP INCORRECTLY LABELED DATA
-Training set
	Output label y are are incorrect, in your training set. 
	If "random error"(Miss typed 0 As 1 etc) then its probably fine to leave in incorrect, but if "Systematic Error" (All white dogs are miss-classified As cats) then these needs to be fixed
-Dev set
	So for this in the above 'ERROR ANALYSIS' table add a column to capture labels that are incorrectly labeled rather than Labels that are incorrectly classified by your model, and see if has a higer impact if yes, make the changes.

-Test set
	Apply same fixing process of Dev set on test set

Fixing in Training set is avoid due to the large amount of data it has, which is ok. Also this may result in the distribution of your Train and Dev/Test set data to differ.

------------------------------------------------------------------------------------------------------------------------------
BUILD YOUR FIRST SYSTEM QUICKLY, THEN ITERATE
"BUILD YOUR FIRST SYSTEM QUICKLY, THEN ITERATE"
Use "Bias/Variance Analysis" and "Error Analysis" to prioritize your next steps.


------------------------------------------------------------------------------------------------------------------------------
------------------------------------------MISMATCHED TRAINING AND DEV/TEST SET------------------------------------------
------------------------------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------------
TRAINING AND TESTING ON DIFFERENT DISTRIBUTIONS
Training and testing on different distributions
Example:
	Training data From Webpages ~ 10,000
	Testing data From Mobile apps ~ 2,000
	Solution 1 : 
		Add both together ~ 12,000 and reshuffle and divide into 90/5/5 - 10,800/600/600 Traing/Dev/Test set
		Adv 	: Data now comes From same distribution
		DisAdv 	: A lot of Data in dev set now comes from Webpages 
				  Since 84% data is From WebPages and 26 is From Mobile apps, 504 images would be From only  WebPages and only 96 would be from Mobile Apps

	Solution 2 : (Better)
		Add 10,000 From webpages and 1,000 images Mobile apps into Train Set
		Add 1,000 images From Mobile apps , 500 each into Dev and test set 
		Adv 	: Model will aim to improve Dev set which has distributions From mobile apps, which matters
		DisAdv 	: Data now DOES NOT come From same distribution into train and Dev/test set
------------------------------------------------------------------------------------------------------------------------------
BIAS AND VARIANCE WITH MISMATCHED DATA DISTRIBUTIONS


------------------------------------------------------------------------------------------------------------------------------
ADDRESSING DATA MISMATCH


------------------------------------------------------------------------------------------------------------------------------
------------------------------------------LEARNING FROM MULTIPLE TASKS------------------------------------------
------------------------------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------------
TRANSFER LEARNING


------------------------------------------------------------------------------------------------------------------------------
MULTI-TASK LEARNING


------------------------------------------------------------------------------------------------------------------------------
------------------------------------------END-TO-END DEEP LEARNING------------------------------------------
------------------------------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------------
WHAT IS END-TO-END DEEP LEARNING?


------------------------------------------------------------------------------------------------------------------------------
WHETHER TO USE END-TO-END DEEP LEARNING



MACHINE LEARNING FLIGHT SIMULATOR
QUIZ: AUTONOMOUS DRIVING (CASE STUDY)


VIDEO - RUSLAN SALAKHUTDINOV




















